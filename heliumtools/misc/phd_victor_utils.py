import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.constants import k as kb
from tqdm import tqdm
from scipy.constants import m_p, hbar
from heliumtools.tools import *
from scipy.optimize import curve_fit
from matplotlib.colors import ListedColormap
from heliumtools.correlations import Correlation
from cycler import cycler
from heliumtools.dataset import Dataset
from heliumtools.correlations import Correlation
from heliumtools.tools import (
    apply_ROI,
    data_filter,
    apply_ROD,
    get_roi_min_max,
    get_roi_center,
)
from heliumtools.misc.some_plots_volume1 import *
from heliumtools.correlations2 import CorrelationHe2Style
from heliumtools.misc.logger import getLogger, logging
from heliumtools.fit.oscillations import Oscillation1DFit
from heliumtools.misc.gather_data import export_data_set_to_pickle
from heliumtools.bec import Gaussian_BEC

m_he = 4 * m_p


def thermal_prof(x, T, Ath):
    return Ath * np.exp(-(x**2) / (2 * T**2))


def phonon_pair(x, x0, sigma, A):
    return A * np.exp(-((x - x0) ** 2) / (2 * sigma**2))


def gaussian_no_offset(x, A, sigma, x0):
    return A * np.exp(-((x - x0) ** 2) / (2 * sigma**2))


def gaussian_with_temp_v2(x, x0_l, sigma_l, A_l, x0_r, sigma_r, A_r, T, Ath, Alas):
    return (
        thermal_prof(x, T, Ath)
        + phonon_pair(x, x0_l, sigma_l, A_l)
        + phonon_pair(x, x0_r, sigma_r, A_r)
        + Alas * np.where(x < 0, 1, 0)
    )


def get_g2(data: pd.DataFrame, axis: str, ROI: dict) -> pd.DataFrame:
    """function that returns the small gÂ² intergrated function along axis.
      The ROI is apllied before integration hence can be understood as integration
      bounds

    Parameters
    ----------
    data : pandas dataframe
        Integrated correlation result dataframe that must contain G2AA, G2AB and G2BB
        and their mean squared and variance. Such dataframe is generated by the
        compute_correlation method as well as the bootstrap one.
    axis : string
        the axis on which one wants to integrate
    ROI : dict
        dictiona

    Returns
    -------
    pd.Dataframe
        g2 integrated over axis
    """
    data = apply_ROI(data, ROI).copy()
    if "G2AA std" in data.columns:
        for G2 in ["G2AA", "G2BB", "G2AB"]:
            data[G2 + " mean squared"] = data[G2 + " mean"] ** 2
            data[G2 + " variance"] = data[G2 + " std"] ** 2
    data = data.groupby(axis).sum().reset_index()
    data_err = data.groupby(axis).mean().reset_index()
    for G2, g2 in zip(["G2AA", "G2BB", "G2AB"], ["g2 aa", "g2 bb", "g2 ab"]):
        data[g2] = data[G2] / data[G2 + " denominator"]
        if G2 + " std" in data.columns:
            data[g2 + " error"] = (
                np.sqrt(data_err[G2 + " squared"] - data_err[G2 + " mean squared"])
                / data[G2 + " denominator"]
            )
            data[g2 + " error bis"] = (
                np.sqrt(data_err[G2 + " variance"]) / data[G2 + " denominator"]
            )
    return data


def fit_pair_density_v3(
    corr, ROI={"Vx": [-50, 50], "Vy": [-50, 50]}, bins=np.arange(5, 20, 0.1), axes=None
):
    bins = np.sort(np.abs(bins))
    # positive peak
    hist_r, bin_edges_r = np.histogram(apply_ROI(corr.atoms, ROI)["Vz"], bins=bins)
    bin_center_r = (bin_edges_r[1:] + bin_edges_r[:-1]) / 2
    # negative peak
    hist_l, bin_edges_l = np.histogram(
        apply_ROI(corr.atoms, ROI)["Vz"], bins=np.sort(-bins)
    )
    bin_center_l = (bin_edges_l[1:] + bin_edges_l[:-1]) / 2
    hist = np.concatenate((hist_l, hist_r))
    bin_center = np.concatenate((bin_center_l, bin_center_r))

    dBin = bins[1] - bins[0]
    hist = hist / dBin / corr.n_cycles
    p0 = [
        bin_center_l[np.argmax(hist_l)],
        1,
        np.max(hist_l),
        bin_center_r[np.argmax(hist_r)],
        1,
        np.max(hist_r),
        8,
        hist[0],
        hist[0],
    ]
    bounds = (
        [-30, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 50, np.inf, 30, 50, np.inf, 200, np.inf, np.inf],
    )
    try:
        popt, pcov = curve_fit(
            gaussian_with_temp_v2, bin_center, hist, p0=p0, bounds=bounds
        )
        perr = np.sqrt(np.diag(pcov))
        T = m_he * (popt[6] / 1000) ** 2 / kb * 1e9  # temperature nK
        dT = float(m_he * (perr[6] / 1000) ** 2 / kb * 1e9)
        res = {
            "Temperature (nK)": float(T),
            "Temperature (mm/s)": float(popt[6]),
            "Temperature error (nK)": dT,
            "Amplitude left (at/mm/s)": float(popt[2]),
            "Width left (mm/s)": float(popt[1]),
            "Width Vz left (mm/s)": float(popt[1]),
            "U(Width Vz left) (mm/s)": float(perr[1]),
            "Position left (mm/s)": float(popt[0]),
            "Amplitude right (at/mm/s)": float(popt[5]),
            "Width right (mm/s)": float(popt[4]),
            "Width Vz right (mm/s)": float(popt[4]),
            "U(Width Vz right) (mm/s)": float(perr[4]),
            "Position right (mm/s)": float(popt[3]),
            "Lasing effect (at/mm/s)": float(popt[8]),
            "Thermal density (at/mm/s)": (
                float(thermal_prof(popt[0], popt[6], popt[7]))
                + float(thermal_prof(popt[3], popt[6], popt[7]))
            )
            / 2,
        }
        # dataset.set(density_positive_peak = T)
    except Exception as e:
        print(f"Failed to fit: {e}")
        popt = p0
        res = {}
        T = np.nan
        return
    try:
        ax = axes[0]
        bins_total = np.arange(-np.max(bins), np.max(bins) + dBin, dBin)
        (
            hist_total,
            b0,
        ) = np.histogram(apply_ROI(corr.atoms, ROI)["Vz"], bins=bins_total)
        hist_total = hist_total / dBin / corr.n_cycles
        ax.plot(
            (bins_total[1:] + bins_total[:-1]) / 2,
            hist_total,
            label="exp",
            color="teal",
        )
        # plot the fit
        for x in [bin_center_l, bin_center_r]:
            ax.plot(
                x,
                gaussian_with_temp_v2(x, *popt),
                label="T = {:.0f} nK".format(T),
                color="indianred",
            )
        ax.set_xlabel("Vz (mm/s)")
        ax.set_ylabel("Atomic density (at/mm/s)")
        ax.set_ylim(top=1.2 * np.max(hist), bottom=0)
    except:
        pass
    dty_color = ["goldenrod", "teal"]
    dty_in_color = ["navajowhite", "skyblue"]
    fit_line = ["indianred", "darkslategrey"]
    markers = ["o", "s"]
    lines = ["--", "-."]
    for j, axis in enumerate(["Vx", "Vy"]):

        for k, peak in enumerate(["left", "right"]):
            data = apply_ROI(
                corr.atoms,
                ROI={
                    "Vz": {
                        "center": res[f"Position {peak} (mm/s)"],
                        "size": 2 * res[f"Width {peak} (mm/s)"],
                    }
                },
            )
            hist, bins = np.histogram(data[axis], np.arange(-35, 35, 2))
            y = hist / np.max(hist)
            x = bins[0:-1]
            ### fit
            func = gaussian_no_offset
            popt, pcov = curve_fit(func, x, y, p0=[1, 5, 0])
            perr = np.sqrt(np.diag(pcov))

            res[f"Width {axis} {peak} (mm/s)"] = float(popt[1])
            res[f"U(Width {axis} {peak}) (mm/s)"] = float(perr[1])
            res[f"Center {axis} {peak} (mm/s)"] = float(popt[2])

            #######
            ## PLOT
            #######
            try:
                ax = axes[j + 1]
                ax.plot(
                    x,
                    y,
                    marker=markers[k],
                    markerfacecolor=dty_in_color[k],
                    markeredgecolor=dty_color[k],
                    markersize=4,
                    alpha=1,
                    ls="",
                )
                ax.set_xlabel(axis + " (mm/s)")

                x_fit = np.linspace(min(x), max(x), 100)
                ax.plot(
                    x_fit,
                    func(x_fit, *popt),
                    ls=lines[k],
                    color=fit_line[k],
                    label=r"{:.1f}({:.0f})".format(np.abs(popt[1]), 10 * perr[1]),
                )
                ax.legend(
                    ncol=1,
                    loc="lower center",
                    fontsize=8,
                    title="$\sigma$ (mm/s)",
                    title_fontsize=8,
                )
            except:
                pass
    return res


def fit_pair_density_v2(
    corr, ROI={"Vx": [-50, 50], "Vy": [-50, 50]}, bins=np.arange(5, 20, 0.1), ax=None
):
    bins = np.sort(np.abs(bins))
    # positive peak
    hist_r, bin_edges_r = np.histogram(apply_ROI(corr.atoms, ROI)["Vz"], bins=bins)
    bin_center_r = (bin_edges_r[1:] + bin_edges_r[:-1]) / 2
    # negative peak
    hist_l, bin_edges_l = np.histogram(
        apply_ROI(corr.atoms, ROI)["Vz"], bins=np.sort(-bins)
    )
    bin_center_l = (bin_edges_l[1:] + bin_edges_l[:-1]) / 2
    hist = np.concatenate((hist_l, hist_r))
    bin_center = np.concatenate((bin_center_l, bin_center_r))

    dBin = bins[1] - bins[0]
    hist = hist / dBin / corr.n_cycles
    p0 = [
        bin_center_l[np.argmax(hist_l)],
        1,
        np.max(hist_l),
        bin_center_r[np.argmax(hist_r)],
        1,
        np.max(hist_r),
        8,
        hist[0],
        hist[0],
    ]
    bounds = (
        [-30, 0, 0, 0, 0, 0, 0, 0, 0],
        [0, 50, np.inf, 30, 50, np.inf, 200, np.inf, np.inf],
    )
    try:
        popt, pcov = curve_fit(
            gaussian_with_temp_v2, bin_center, hist, p0=p0, bounds=bounds
        )
        perr = np.sqrt(np.diag(pcov))
        T = m_he * (popt[6] / 1000) ** 2 / kb * 1e9  # temperature nK
        dT = float(m_he * (perr[6] / 1000) ** 2 / kb * 1e9)
        res = {
            "Temperature (nK)": float(T),
            "Temperature (mm/s)": float(popt[6]),
            "Temperature error (nK)": dT,
            "Amplitude left (at/mm/s)": float(popt[2]),
            "Width left (mm/s)": float(popt[1]),
            "Position left (mm/s)": float(popt[0]),
            "Amplitude right (at/mm/s)": float(popt[5]),
            "Width right (mm/s)": float(popt[4]),
            "Position right (mm/s)": float(popt[3]),
            "Lasing effect (at/mm/s)": float(popt[8]),
            "Thermal density (at/mm/s)": (
                float(thermal_prof(popt[0], popt[6], popt[7]))
                + float(thermal_prof(popt[3], popt[6], popt[7]))
            )
            / 2,
        }
        # dataset.set(density_positive_peak = T)
    except Exception as e:
        print(f"Failed to fit: {e}")
        popt = p0
        res = {}
        T = np.nan
    if ax:
        bins_total = np.arange(-np.max(bins), np.max(bins) + dBin, dBin)
        (
            hist_total,
            b0,
        ) = np.histogram(apply_ROI(corr.atoms, ROI)["Vz"], bins=bins_total)
        hist_total = hist_total / dBin / corr.n_cycles
        ax.plot(
            (bins_total[1:] + bins_total[:-1]) / 2,
            hist_total,
            label="exp",
            color="teal",
        )
        # plot the fit
        for x in [bin_center_l, bin_center_r]:
            ax.plot(
                x,
                gaussian_with_temp_v2(x, *popt),
                label="T = {:.0f} nK".format(T),
                color="indianred",
            )
        ax.set_xlabel("Vz (mm/s)")
        ax.set_ylabel("Atomic density (at/mm/s)")
        ax.set_ylim(top=1.2 * np.max(hist), bottom=0)
    return res


def get_correlation_many(
    corr,
    N_bootstrap=10,
    Vz_range=[7, 12],
    box_Z_size=[0.3, 0.5, 0.7, 0.9],
    box_XY_size=[80],
    ratio_size={"Vx": 1, "Vy": 1, "Vz": 1},
    DV=0.8,
):
    """fonction qui retourne un gros dataframe avec les propriÃ©tÃ©s de corrÃ©lations pour diffÃ©rentes positions de boÃ®tes Vz1 et Vz2. La fonction commence par rÃ©cupÃ©rer le maximum de densitÃ© croisÃ©e pour ensuite calculer les corrÃ©lations autour de celle-ci (dans un espace DV autour).


    Parameters
    ----------
    path : _type_
        _description_
    N_bootstrap : int, optional
        _description_, by default 10

    Returns
    -------
    _type_
        _description_
    """
    COLUMNS = [
        "Vz1",
        "Vz2",
        "g^2",
        "N_1",
        "N_2",
        "g^2(k2,k2)",
        "g^2(k1,k1)",
        "N_1*N_2",
        "normalized variance",
        "g^4",
        "C-S difference",
        "denis",
        "denis2",
        "Delta",
        "-Delta",
    ]
    TOTAL = []
    # la taille qu'on s'autorise pour aller chercher des corrÃ©lations
    corr.boxes["1"] = {
        "Vz": {"position": -9.2, "size": 1},
        "Vx": {"position": 0, "size": 80},
        "Vy": {"position": 0, "size": 80},
    }
    corr.boxes["2"] = {
        "Vz": {"position": 9.2, "size": 1},
        "Vx": {"position": 0, "size": 80},
        "Vy": {"position": 0, "size": 80},
    }
    corr.define_variable1(
        box="1",
        axe="Vz",
        type="position",
        name="Vz1",
        min=-np.max(Vz_range),
        max=-np.min(Vz_range),
        step=0.1,
    )
    corr.define_variable2(
        box="2",
        axe="Vz",
        type="position",
        name="Vz2",
        min=np.min(Vz_range),
        max=np.max(Vz_range),
        step=0.1,
    )
    corr.remove_shot_noise = False
    corr.compute_correlations()
    # on rÃ©cupÃ¨re le maximum de corrÃ©lation non normalisÃ©e
    serie = corr.result.loc[np.argmax(corr.result["N_1*N_2"])]
    Vz1 = serie.loc["Vz1"]
    Vz2 = serie.loc["Vz2"]
    for boxZsize in tqdm(box_Z_size):
        for boxXYsize in box_XY_size:

            # we now loop over the difference situations
            corr.boxes["1"]["Vz"]["size"] = boxZsize * ratio_size["Vz"]
            corr.boxes["1"]["Vx"]["size"] = boxXYsize * ratio_size["Vx"]
            corr.boxes["1"]["Vy"]["size"] = boxXYsize * ratio_size["Vy"]
            corr.boxes["2"]["Vz"]["size"] = boxZsize
            corr.boxes["2"]["Vx"]["size"] = boxXYsize
            corr.boxes["2"]["Vy"]["size"] = boxXYsize

            corr.define_variable1(
                box="1",
                axe="Vz",
                type="position",
                name="Vz1",
                min=Vz1 - DV,
                max=Vz1 + DV,
                step=0.1,
            )
            corr.define_variable2(
                box="2",
                axe="Vz",
                type="position",
                name="Vz2",
                min=Vz2 - DV,
                max=Vz2 + DV,
                step=0.1,
            )
            corr.compute_correlations()
            res = []
            final_df = corr.result.loc[:, COLUMNS]
            corr.save_copy_of_total()
            for kboot in range(N_bootstrap):
                corr.bootstrap_total()
                corr.compute_result(corr.total)
                res.append(corr.result)
            res = pd.concat(res)
            res_mean = res.groupby(["Vz1", "Vz2"]).mean().reset_index()
            res_err = res.groupby(["Vz1", "Vz2"]).std().reset_index()
            for key in [
                "g^2",
                "N_1",
                "N_2",
                "g^2(k2,k2)",
                "g^2(k1,k1)",
                "N_1*N_2",
                "normalized variance",
                "g^4",
                "C-S difference",
                "denis",
                "denis2",
                "Delta",
                "-Delta",
            ]:
                final_df["Mean " + key] = res_mean[key]
                final_df["U(" + key + ")"] = res_err[key]
            final_df["boxXYsize"] = boxXYsize
            final_df["boxZsize"] = boxZsize
            final_df["boxZsize1"] = boxZsize
            final_df["boxZsize2"] = boxZsize
            TOTAL.append(final_df)
    return pd.concat(TOTAL).reset_index(drop=True)


def show_vz_correlations(corr, VXY_list=[100, 50, 8], VZ_span=[-12, 12]):
    """function that take as an input a IntegratedCorrelation class and show the integrated g2 along z

    Parameters
    ----------
    corr : CorrelationHe2Style
        Correlation already calculated.
    VXY_list : list, optional
        transverse integration volume list for all plots, by default [100, 50, 8]
    VZ_span : list, optional
        longitudinal ROI, that are the span of the axes., by default [-12, 12]
    """
    fig, axes = plt.subplots(
        figsize=(11, 4),
        ncols=3,
    )
    axis = "Vz"
    # -- Set style
    custom_cycler1 = cycler(
        color=[plt.get_cmap("magma")(i) for i in range(0, 256, 256 // len(VXY_list))]
    )
    axes[2].set_prop_cycle(custom_cycler1)
    custom_cycler2 = cycler(
        color=[plt.get_cmap("viridis")(i) for i in range(0, 256, 256 // len(VXY_list))]
    )
    axes[0].set_prop_cycle(custom_cycler2)
    axes[1].set_prop_cycle(custom_cycler2)
    markers = ["o", "v", "s", "d", "p", "*", "H", "P", "<", "+"] * 3
    lines = ["--", "-.", ":"] * 10
    for j, vxy in enumerate(VXY_list):
        ROI = {
            "Vx": {"position": 0, "size": 2 * vxy},
            "Vy": {"position": 0, "size": 2 * vxy},
            "Vz": VZ_span,
        }
        for i, TO_PLOT in enumerate(["g2 aa", "g2 bb", "g2 ab"]):
            ax = axes[i]
            df = get_g2(corr.result, axis, ROI)
            x = df[axis]
            y = df[TO_PLOT]
            yerr = df[TO_PLOT + " error"]
            ax.errorbar(
                x, y, yerr=yerr, fmt=markers[j], label="{}".format(vxy), alpha=0.7
            )
    for ax in axes:
        ax.legend(fontsize="small", title=r"$\delta V_\perp$")
        ax.grid(True, alpha=0.5)
        ax.set_xlabel("$\delta {} = k_{{Z,1}} -k_{{Z,2}}  $ (mm/s)".format(axis))
        ax.set_ylabel("$\int g^{{(2)}}(k, k+\delta k_z) dk_z$")
    axes[2].set_xlabel("$\delta {} = k_{{Z,1}} + k_{{Z,2}}  $ (mm/s)".format(axis))

    ## Style
    if corr.cross_correlation_sign["Vx"] > 0:
        sign = "+"
    else:
        sign = "-"
    title = f"Crossed correlations function (sign:${sign}$) \n in inertial frame "
    title += r"$\vec{{V}}$=({}, {}, {}) mm/s ".format(
        corr.ref_frame_speed["Vx"],
        corr.ref_frame_speed["Vy"],
        corr.ref_frame_speed["Vz"],
    )
    axes[2].set_title(title, fontsize="medium")

    if get_roi_center(corr.beams["A"], "Vz") > 0:
        title = r" ($V_z > 0$)."
    else:
        title = r" ($V_z < 0$)."
    axes[0].set_title("Beam A local correlations" + title, fontsize="medium")
    if get_roi_center(corr.beams["B"], "Vz") > 0:
        title = r" ($V_z > 0$)."
    else:
        title = r" ($V_z < 0$)."
    axes[1].set_title("Beam B local correlations" + title, fontsize="medium")
    plt.tight_layout()
    plt.show()


import matplotlib


def get_centered_colormap(
    colormap_name: str, mini: float, maxi: float, center: float
) -> matplotlib.colormaps:
    """function that returns a colormap centered on center and with boundaries mini and maxi.

    Parameters
    ----------
    colormap_name : str
        name of the colormap
    mini : float
        minimum value for the colormap
    maxi : float
        maximum value for the colormap
    center : float
        center of the colormap

    Returns
    -------
    matplotlib.colormaps
        corlorma centered and beatifull for your graph <3
    """

    from matplotlib import cm
    from matplotlib.colors import ListedColormap, LinearSegmentedColormap

    scale = maxi - mini
    ratio_mini = (center - mini) / scale
    ratio_maxi = (maxi - center) / scale
    if ratio_mini > ratio_maxi:
        np_maxi = 130
        np_mini = int(np_maxi * ratio_mini / ratio_maxi)
    else:
        np_mini = 130
        np_maxi = int(np_mini * ratio_maxi / ratio_mini)
    cmap_mini = plt.get_cmap(colormap_name, 2 * np_mini)
    mini_val = cmap_mini(np.linspace(0, 1, 2 * np_mini))[0:np_mini]
    cmap_maxi = plt.get_cmap(colormap_name, 2 * np_maxi)
    maxi_val = cmap_maxi(np.linspace(0, 1, 2 * np_maxi))[np_maxi:-1]
    my_colormap = ListedColormap(list(mini_val) + list(maxi_val))
    return my_colormap


def sinus_card(x, A, sigma, x0):
    return A * np.sinc((np.abs((x - x0) / (2 * sigma))) ** (1)) + 1


def sinus_card_sqrt(x, A, sigma, x0):
    return A * np.sinc((np.abs((x - x0) / (2 * sigma))) ** (1 / 2)) + 1


def lorentzian(x, A, sigma, x0):
    return 1 + A * (1 / (1 + (x - x0) ** 2 / (sigma) ** 2))


def lorentzian2(x, A, sigma, x0):
    return 1 + A * (1 / (1 + (x - x0) ** 2 / (sigma) ** 2) ** 2)


def gaussian(x, A, sigma, x0):
    return 1 + A * np.exp(-((x - x0) ** 2) / (2 * sigma**2))


def expo(x, A, sigma, x0):
    return 1 + A * np.exp(-np.abs(x - x0) / sigma)


class CorrelationKmK(Correlation):
    def compute_kmk_correlations(self, dk_optimisation=0.3, optimizer="N_1*N_2"):
        """Function that compute the corration between k and -k.


        Parameters
        ----------
        dk_optimisation : float, optional
            range to optimize, by default 0.3
        optimizer : str, optional
            _description_, by default "N_1*N_2"
        """
        self.compute_correlations()

        self.filter_result_kmk(dk_optimisation=dk_optimisation, optimizer=optimizer)

    def filter_result_kmk(self, dk_optimisation=0.3, optimizer="N_1*N_2"):
        """filter out the result dataframe to get only (k,-k) correlations.

        Parameters
        ----------
        dk_optimisation : float, optional
            range to optimize, by default 0.3
        optimizer : str, optional
            _description_, by default "N_1*N_2"
        """
        self.result = apply_ROI(
            self.result,
            ROI={
                f"{self.var1.name}+{self.var2.name}": [
                    -dk_optimisation,
                    dk_optimisation,
                ]
            },
        )
        self.result = self.result.sort_values(
            optimizer, ascending=False
        ).drop_duplicates([f"{self.var1.name}-{self.var2.name}"])
        self.result["k"] = self.result[f"{self.var1.name}-{self.var2.name}"] / 2
        self.result = self.result.sort_values("k")

    def set_size_with_ratio(
        self, dVz, dVx, dVy, ratio_size={"Vx": 1, "Vy": 1, "Vz": 1}
    ):
        """set the boxes size taking itnot account the discrepancy between the size of the mode.

        Parameters
        ----------
        dVz : float
            size of the box along Vz (box 2 size (right peak))
        dVx : float
            size of the box along Vx (box 2 size (right peak))
        dVy : float
            size of the box along Vy (box 2 size (right peak))
        ratio_size : dict, default {"Vz":1, "Vy":1, "Vz":1}
            ratio of the size
        """
        self.boxes["1"]["Vz"]["size"] = dVz * ratio_size["Vz"]
        self.boxes["1"]["Vx"]["size"] = dVx * ratio_size["Vx"]
        self.boxes["1"]["Vy"]["size"] = dVy * ratio_size["Vy"]
        self.boxes["2"]["Vz"]["size"] = dVz
        self.boxes["2"]["Vx"]["size"] = dVx
        self.boxes["2"]["Vy"]["size"] = dVy


from scipy.special import factorial, gamma
from heliumtools.tools import apply_ROI, data_filter, get_roi_size

# import thewalrus

from scipy.special import factorial, gamma
from heliumtools.tools import apply_ROI, data_filter, get_roi_size


def thermal_distribution(x, moy):
    """DÃ©finie une loi de probabilitÃ© thermique via la moyenne de la loi"""
    return (moy / (1 + moy)) ** x / (1 + moy)


def poissonian_distribution(x, moy):
    """DÃ©finie une loi de probabilitÃ© poissonnienne via la moyenne de la loi"""
    return np.exp(-moy) * moy**x / factorial(x)


def fit_multimode_thermal_distribution(x, px, moy, perr=None):
    """Fit une loi de probabilitÃ© thermique multimode. Le seul paramÃ¨tre libre de
    fit est le nombre de mode. La population moyenne Ã©tant 'mesurÃ©e'. C'est pour
    cela que la fonction est loi de probabilitÃ© multimmode thermique est dÃ©finie
    dans cette fonction et non en dehors."""

    def proba_multimode(n, n_modes):
        """DÃ©finie une loi de probabilitÃ© multimode thermique via la moyenne
        (censÃ© Ãªtre un argument mais gardÃ© fixe ici pour le fit), et le nombre de modes.
        """
        return (
            gamma(n + n_modes)
            / (gamma(n + 1) * gamma(n_modes))
            * (1 + n_modes / moy) ** (-n)
            * (1 + moy / n_modes) ** (-n_modes)
        )

    popt, pcov = curve_fit(proba_multimode, x, px, p0=[1], bounds=(0.1, 30))
    perr = np.sqrt(np.diag(pcov))
    return popt[0], perr[0], proba_multimode(x, *popt)


def proba_multimode_plot(n, n_modes, moy):
    """DÃ©finie une loi de probabilitÃ© multimode thermique via la moyenne
    (censÃ© Ãªtre un argument mais gardÃ© fixe ici pour le fit), et le nombre de modes."""
    return (
        gamma(n + n_modes)
        / (gamma(n + 1) * gamma(n_modes))
        * (1 + n_modes / moy) ** (-n)
        * (1 + moy / n_modes) ** (-n_modes)
    )


def get_proba_distribution(correl, box_num="1"):
    """return the probability distribution of one of the box of the atoms from the class Correlations correl

    Parameters
    ----------
    correl : Correlation
        the correlation class from which one wants the probability distribution
    box_num : str, optional "1" or "2"
        box number of the correlation class , by default "1"
    """
    at = correl.obtain_number_of_atoms_per_cycle_in_box(
        correl.atoms, correl.boxes[box_num], "N"
    )
    at["Probability"] = np.ones(len(at))
    # on dÃ©finie df, dataframe qui donne le nombre d'atome
    df = at.groupby("N").count().reset_index()
    df["Probability"] = df["Probability"] / np.sum(df["Probability"])
    df["Probability error"] = np.sqrt(df["Probability"]) / np.sqrt(len(at))
    mean_at_num = np.sum(df["Probability"] * df["N"])
    mean_at_num2 = np.sum(at["N"]) / len(at)
    if np.abs(mean_at_num - mean_at_num2) > 1e-8:
        print("Something is wrong with the mean in the calculation.")
    return mean_at_num2, df


class CorrelationFCS(Correlation):
    def __init__(self, atoms, **kwargs):
        """
        Object initialization, sets parameters as the user defined, build the atoms dataframe and apply ROD and ROI.
        """
        super().__init__(atoms, **kwargs)

    def compute_fcs(self, N_boostrap=10, correlation_max=4):
        self.var2 = None
        self.compute_correlations()
        ### choose only some columns
        self.total = self.total[["Cycle", "N_1", self.var2.name, self.var1.name, "N_2"]]
        self.probability = self.get_probability(correlation_max=correlation_max)
        self.gn = self.get_gn(self.probability)
        self.save_copy_of_total()
        bootstrap_result = []
        for j in range(N_boostrap):
            self.bootstrap_total()
            proba = self.get_probability(correlation_max=correlation_max)
            gn = self.get_gn(proba)
            gn["Bootstrap"] = j
            bootstrap_result.append(gn)
        bootstrap_result = pd.concat(bootstrap_result)
        bootstrap_result = (
            bootstrap_result.groupby([self.var1.name, "order n"]).std().reset_index()
        )
        for col in bootstrap_result.columns:
            if col not in [self.var1.name, "order n"]:
                bootstrap_result.rename(columns={col: f"U({col})"}, inplace=True)
        self.gn = self.gn.merge(bootstrap_result, on=[self.var1.name, "order n"])

    def get_gn(self, probability):
        exist = True
        i = 1
        g_n = []
        probability["Nmean"] = probability["Probability"] * probability["N_1"]
        while exist:
            try:
                probability[f"G^n"] = (
                    probability["Probability"] * probability[f":n^{i}:"]
                )
                new_gn = (
                    probability.groupby(self.var1.name)
                    .sum()[["G^n", "Nmean"]]
                    .reset_index()
                )
                new_gn["order n"] = i
                new_gn["g^n"] = new_gn["G^n"] / new_gn["Nmean"] ** i
                new_gn["g^nth"] = factorial(i)
                g_n.append(new_gn)
            except Exception as e:
                exist = False
            i += 1

        return pd.concat(g_n)

    def get_probability(self, correlation_max=4):
        probability = (
            self.total.groupby(["N_" + self.var1.box, self.var1.name])
            .count()[["Cycle"]]
            .reset_index()
            .rename(columns={"Cycle": "Probability"})
        )
        probability["Probability"] = probability["Probability"] / self.n_cycles
        gn_list = []
        probability[":n^1:"] = probability["N_1"]
        for i in range(2, correlation_max + 1):
            probability[f":n^{i}:"] = probability[f":n^{i-1}:"] * (
                probability["N_1"] - i + 1
            )

        return probability


def add_FCS_on_ax(
    correl,
    ax,
    box_num="1",
    color="goldenrod",
    style="o",
    poisson="teal",
    thermal="indianred",
):
    """Function to show full counting statistics"""
    mean, df = get_proba_distribution(correl, box_num=box_num)
    ### AJOUT DE L'INSET
    L, W = 0.5, 0.5
    ax_ins = ax.inset_axes([1 - L, 1 - W, L, W])
    # n_modes, deltan_modes, pth = fit_multimode_thermal_distribution(df["N"].to_numpy(),
    #                                                               df["Probability"].to_numpy(),
    #                                                               moy,
    #                                                               perr = df["Probability error"].to_numpy())

    x = np.linspace(0, np.max(df["N"]) + 2, 300)
    # pth_plot = proba_multimode_plot(x,n_modes ,moy)
    for a in [ax, ax_ins]:
        dN_th = np.sqrt(mean**2 + mean) / mean / np.sqrt(correl.n_cycles)
        a.plot(x, thermal_distribution(x, mean), color=thermal, alpha=1)
        ax.fill_between(
            x,
            thermal_distribution(x, mean - dN_th),
            thermal_distribution(x, mean + dN_th),
            color=thermal,
            alpha=0.1,
        )
        a.plot(x, poissonian_distribution(x, mean), color="teal", ls="--")
        dN_p = np.sqrt(mean) / mean / np.sqrt(correl.n_cycles)
        ax.fill_between(
            x,
            poissonian_distribution(x, mean - dN_p),
            poissonian_distribution(x, mean + dN_p),
            color=poisson,
            alpha=0.1,
        )
        a.errorbar(
            df["N"],
            df["Probability"],
            yerr=df["Probability error"],
            fmt=style,
            color=color,
            markeredgecolor=color,
            markerfacecolor="#ffffff00",
            label=r"$\bar N =${:.1f}".format(mean),
        )
        a.grid(True, alpha=0.5)
    print(dN_th)
    # ax.plot(x,pth_plot, label = r"$\bar M_{{modes}}=${:.1f}({})".format(n_modes, round(10*deltan_modes)), ls = "--", color = "black", alpha = 0.7)
    df["PobaErr2"] = np.sqrt(thermal_distribution(df["N"], mean) / correl.n_cycles)

    # ax_ins.errorbar(df["N"], df["Probability"], yerr = df["PobaErr2"],
    #             fmt = "o", color = "steelblue", markerfacecolor= "lightblue",
    #             markersize = 4,
    #             label = r"$\bar N =${:.1f}".format(mean), alpha = 1)
    ax_ins.set_xlim([-0.3, max(3 * mean, 3.3)])
    ytick = list(np.arange(0, ax.get_ylim()[1], 0.1))
    ytick_lab = [str(round(i, 1)) for i in ytick]
    ytick_lab[0] = "0"
    ax_ins.set_yticks(ytick)
    ax_ins.set_yticklabels(ytick_lab, fontsize="small")
    ax.set_yscale("log")
    # ax_ins.set_yticklabels(ax_ins.get_yticks(), fontsize='small')
    print(ax_ins.get_ylim())

    # ax_ins.set_xticks(ax.get_xticks())
    ax.set_ylim(bottom=0.5 * np.min(df["Probability"]))


def show_correlations_heatmaps(corr):
    nrows = 2
    ncols = 4
    fig, axes = plt.subplots(figsize=(4 * ncols, 3.3 * nrows), nrows=nrows, ncols=ncols)
    axes = axes.flatten()
    CMAP_PROP = {
        "g^2": {"cmap": "BrBG", "vmin": 1, "vmax": 2.3, "center": 2},
        "normalized variance": {"cmap": "seismic", "vmin": 0.8, "vmax": 2, "center": 1},
        "C-S": {"cmap": "seismic", "vmin": 0.5, "vmax": 1.1, "center": 1},
        "g^2 loc": {"cmap": "BrBG", "vmin": 1, "vmax": 2.3, "center": 2},
        "C-S difference": {
            "cmap": "seismic",
            "vmin": corr.result["C-S difference"].min(),
            "vmax": corr.result["C-S difference"].max(),
            "center": 0,
        },
    }
    corr.result["g^2 loc"] = (
        0.5 * corr.result["g^2(k1,k1)"] + 0.5 * corr.result["g^2(k2,k2)"]
    )
    corr.result.loc[corr.result["g^2"] == np.nan, "g^2"] = 1
    corr.result.loc[corr.result["C-S"] == np.nan, "C-S"] = 1
    corr.result.loc[corr.result["C-S difference"] == np.nan, "C-S difference"] = 0
    heatmap_with_boxes(
        ax=axes[0],
        df=corr.result,
        boxes={},
        columns=corr.var1.name,
        index=corr.var2.name,
        values="N_1*N_2",
        cmap="viridis",
    )
    axes[0].set_title(f"N1*N2", fontsize="medium")
    for j, TO_show in enumerate(
        ["g^2", "C-S", "normalized variance", "g^2 loc", "C-S difference"]
    ):
        ax = axes[j + 1]
        cmap = get_centered_colormap(
            CMAP_PROP[TO_show]["cmap"],
            CMAP_PROP[TO_show]["vmin"],
            CMAP_PROP[TO_show]["vmax"],
            CMAP_PROP[TO_show]["center"],
        )
        cmap.set_bad("grey")
        heatmap_with_boxes(
            ax=ax,
            df=corr.result,
            boxes={},
            columns=corr.var1.name,
            index=corr.var2.name,
            values=TO_show,
            vmax=CMAP_PROP[TO_show]["vmax"],
            vmin=CMAP_PROP[TO_show]["vmin"],
            cmap=cmap,
        )
        ax.set_title(TO_show)

    df1 = corr.result[corr.result[corr.var1.name] == corr.result[corr.var1.name].min()]
    df2 = corr.result[corr.result[corr.var2.name] == corr.result[corr.var2.name].min()]
    ax = axes[-2]
    ax.set_xlabel("|Vz| (mm/s)")
    ax.set_ylabel("$g^{(2)}_{k,k}$")

    ax.plot(-df2[corr.var1.name], df2["g^2(k1,k1)"], label="-")
    ax.plot(df1[corr.var2.name], df1["g^2(k2,k2)"], label="+")
    ax = axes[-1]
    ax.plot(-df2[corr.var1.name], df2["N_1"], label="-")
    ax.plot(df1[corr.var2.name], df1["N_2"], ls="--", label="+")
    ax.set_xlabel("|Vz| (mm/s)")
    ax.set_ylabel("Population")
    for ax in axes[0:-2]:
        ax.plot(np.flip(corr.var1.values), corr.var2.values, ls="--", color="white")
    fig.suptitle(
        "Arrival time : {:.4f} ms and inertial frame: {}".format(
            corr.theoretical_arrival_time, corr.ref_frame_speed
        )
    )
    plt.tight_layout()
    plt.show()


def show_n_order_correlation(corr):
    """show the nth order correation function and the full counting statitstics of
    a correlation with only 1 variable.

    Parameters
    ----------
    corr : _type_
        _description_
    """
    corr.define_variable1(
        box="1",
        axe="Vz",
        type="position",
        name="Vz1",
        values=[corr.boxes["1"]["Vz"]["position"]],
    )
    corr.define_variable2(
        box="2",
        axe="Vz",
        type="position",
        name="Vz2",
        values=[corr.boxes["2"]["Vz"]["position"]],
    )
    corr.compute_correlations()
    corr.save_copy_of_total()
    df = []
    for n in range(50):
        corr.bootstrap_total()
        corr.compute_result(corr.total)
        df.append(corr.result)
    df = pd.concat(df)
    df["g_1^(1)"] = 1
    df["g_2^(1)"] = 1
    corr.result = df.groupby(["Vz1", "Vz2"]).mean().reset_index()

    corr.error = df.groupby(["Vz1", "Vz2"]).std().reset_index()
    fig, axes = plt.subplots(ncols=4, figsize=(12, 3))
    # color = color_l[i],style = markers[i]
    add_FCS_on_ax(corr, axes[0], box_num="1", color="tan")
    add_FCS_on_ax(corr, axes[1], box_num="2", color="tan")
    axes[0].legend(loc=3)
    axes[1].legend(loc=3)
    axes[0].set_xlabel("Number of atoms")
    axes[1].set_xlabel("Number of atoms")

    df = pd.DataFrame({"n": np.arange(1, corr.correlation_order_max + 1, 1)})

    for i in range(len(df)):
        n = df.loc[i, "n"]
        for j in range(1, 3):

            df.loc[i, f"g_{j}^(n)"] = corr.result.loc[0, f"g_{j}^({n})"]
            df.loc[i, f"U(g_{j}^(n))"] = float(corr.error.loc[0, f"g_{j}^({n})"])
            df.loc[i, f"g_{j}^(n)/n!"] = corr.result.loc[0, f"g_{j}^({n})"] / factorial(
                n
            )
            df.loc[i, f"U(g_{j}^(n)/n!)"] = float(
                corr.error.loc[0, f"g_{j}^({n})"]
            ) / factorial(n)

    n_vector = np.arange(1, corr.correlation_order_max + 0.1, 1)
    nfactor = factorial(n_vector)
    ax = axes[2]
    ### zoom
    decalage = 1 / 7
    size = 0.12
    sizeh = 0.3
    markers = "os<>"
    axin_l = [
        ax.inset_axes([0.17, 0.3, size, sizeh]),
        ax.inset_axes([0.35, 0.65, size, sizeh]),
    ]
    colors = ["teal", "orange"]
    labels = ["-", "+"]
    for i in range(1, 3):
        ax.errorbar(
            df["n"] - (i - 1.5) * decalage,
            df[f"g_{i}^(n)"],
            yerr=df[f"U(g_{i}^(n))"],
            fmt=markers[i],
            color=colors[i - 1],
            label=labels[i - 1],
            markerfacecolor="#ffffff00",
            markeredgecolor=colors[i - 1],
        )
        axes[3].errorbar(
            df["n"] - (i - 1.5) * decalage,
            df[f"g_{i}^(n)/n!"],
            yerr=df[f"U(g_{i}^(n)/n!)"],
            fmt=markers[i],
            color=colors[i - 1],
            label=labels[i - 1],
            markerfacecolor="#ffffff00",
            markeredgecolor=colors[i - 1],
        )
    ax.legend(loc=4)
    ## theory
    ax.plot(n_vector, nfactor, color="indianred", label="n!")
    for k, axin in enumerate(axin_l):
        axin.set_xlim([k + 2 - 0.3, k + 2 + 0.3])
        axin.set_ylim([factorial(k + 2) * (1 - 0.2), factorial(k + 2) * (1 + 0.2)])
        for i in range(1, 3):
            axin.errorbar(
                df["n"] - (i - 1.5) * decalage,
                df[f"g_{i}^(n)"],
                yerr=df[f"U(g_{i}^(n))"],
                fmt=markers[i],
                color=colors[i - 1],
                markerfacecolor="#ffffff00",
                markeredgecolor=colors[i - 1],
            )
        axin.plot(n_vector, nfactor, color="indianred", label="n!")
        axin.set_yticklabels(np.round(axin.get_yticks(), 2), fontsize="small")
        axin.set_xticks([])
        axin.grid(True, alpha=0.5)
        ax.indicate_inset_zoom(axin)
    ax.grid(True, alpha=0.5)
    axes[3].grid(True, alpha=0.5)
    ax.set_yscale("log")
    plt.show()
    print(corr.result[["g^2", "C-S", "N_1", "N_2", "normalized variance"]])
    print(corr.error[["g^2", "C-S", "N_1", "N_2", "normalized variance"]])


def show_correlation_kmk_optimized(
    corr, range_l=(10, 12), optimizer="g^2", show=True, DV=0.3
):

    corr.define_variable1(
        box="1",
        axe="Vz",
        type="position",
        name="Vz1",
        min=-max(range_l),
        max=-min(range_l),
        step=0.1,
    )
    corr.define_variable2(
        box="2",
        axe="Vz",
        type="position",
        name="Vz2",
        min=min(range_l),
        max=max(range_l),
        step=0.1,
    )
    corr.compute_correlations()
    res_mean0 = corr.result
    corr.save_copy_of_total()
    res = []
    for i in tqdm(range(30)):
        corr.bootstrap_total()
        corr.compute_result(corr.total)
        res.append(corr.result)
    res = pd.concat(res)
    res_std = res.groupby([corr.var1.name, corr.var2.name]).std().reset_index()
    # res_mean = res.groupby([corr.var1.name, corr.var2.name]).mean().reset_index()
    res_mean = res_mean0
    for col in res_std.columns:
        res_mean[f"U({col})"] = res_std[col]
        # res_mean[f"{col} for opti"] = res_mean[col]-  res_mean[f"U({col})"]
    res_mean = apply_ROI(res_mean, {"Vz1+Vz2": {"position": 0, "size": DV}})
    df = (
        res_mean.sort_values(optimizer, ascending=False)
        .drop_duplicates([f"Vz1-Vz2"])
        .reset_index(drop=True)
    )
    if show:
        fig, axes = plt.subplots(ncols=6, nrows=1, figsize=(5 * 3, 2.8))
        for j, col in enumerate(["N_1*N_2", "Delta", "g^2", "C-S", "g^4"]):
            ax = axes[j]
            ax.errorbar(np.abs(df["(Vz1-Vz2)/2"]), df[col], yerr=df[f"U({col})"], ls="")
            ax.set_ylabel(col)
            ax.grid(True, alpha=0.5)
            ax.set_xlabel("$|v_z|$ (mm/s)")
            # ax.set_xlim([8,10])
        for col in ["g^2(k1,k1)", "g^2(k2,k2)"]:
            axes[-1].errorbar(
                np.abs(df["(Vz1-Vz2)/2"]), df[col], yerr=df[f"U({col})"], ls=""
            )
            axes[-1].grid(True, alpha=0.5)
            ax.set_xlabel("$|v_z|$ (mm/s)")
            ax.set_ylabel("$g^{(2)}(k,k)$")
            ax.legend(["-k", "+k"])
        plt.tight_layout()
        plt.show()
    return res_mean
